{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`terminal` - zmiena należąca do [Unicode Private Use Area](https://en.wikipedia.org/wiki/Private_Use_Areas), w ogólności powinno wystarczyć nawet na tekst z emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "terminal = chr(0xF0000) # unique last symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trie:\n",
    "    class _Node:\n",
    "        def __init__(self, letter, parent=None, children=None, link=None, pref_len=0):\n",
    "            self.letter = letter\n",
    "            self.parent = parent\n",
    "            self.children = {} if not children else children\n",
    "            self.link = link\n",
    "            self.len = pref_len\n",
    "        \n",
    "        def add(self, child):\n",
    "            if child.letter in self.children:\n",
    "                raise RuntimeError('Undefined behavior')\n",
    "            self.children[child.letter] = child\n",
    "        \n",
    "        def __getitem__(self, key):\n",
    "            return self.children[key]\n",
    "        \n",
    "        def __contains__(self, key):\n",
    "            return key in self.children\n",
    "        \n",
    "        def __len__(self):\n",
    "            return self.len\n",
    "        \n",
    "    def __init__(self, text=None):\n",
    "        self.root = self._Node(letter='', pref_len=0)\n",
    "        self.root.link = self.root\n",
    "        self.root.parent = None\n",
    "        \n",
    "        if text:\n",
    "            self.build(text)\n",
    "    \n",
    "    def _validate_and_add(self, text):\n",
    "        if text[-1] == terminal:\n",
    "            return text\n",
    "        else:\n",
    "            return text + terminal\n",
    "        \n",
    "    def build(self, text):\n",
    "        text = self._validate_and_add(text)\n",
    "        head = self.root\n",
    "        \n",
    "        for i in range(len(text)):\n",
    "            #if (i+1) % 1000 == 0: print(i+1, '/', len(text))\n",
    "            leaf = self.add(text, i, head)\n",
    "            head = self.up_link_down(leaf)\n",
    "    \n",
    "    def add(self, text, suffix_start, head):\n",
    "        leaf = head\n",
    "        for i in range(suffix_start+len(head), len(text)):\n",
    "            new_node = self._Node(parent = leaf, letter=text[i], pref_len=len(leaf)+1)\n",
    "            leaf.add(new_node)\n",
    "            leaf = new_node\n",
    "            \n",
    "        return leaf\n",
    "    \n",
    "    def up_link_down(self, leaf):\n",
    "        q = [] # works A LOT faster than LifoQueue (on 10^6 elements x30 faster)\n",
    "        prev_branch = leaf\n",
    "        while prev_branch.link is None:\n",
    "            q.append(prev_branch.letter)\n",
    "            prev_branch = prev_branch.parent\n",
    "        \n",
    "        new_head = prev_branch.link\n",
    "        if prev_branch is self.root:\n",
    "            l = q.pop()\n",
    "            self.root[l].link = self.root\n",
    "            prev_branch = self.root[l]\n",
    "        \n",
    "        while q and q[-1] in new_head:\n",
    "            l = q.pop()\n",
    "            prev_branch = prev_branch[l]\n",
    "            new_head = new_head[l]\n",
    "            prev_branch.link = new_head\n",
    "        return new_head\n",
    "    \n",
    "    def find_prefix(self, text, suffix_start, start_node=None): # used erlier\n",
    "        node = start_node if start_node else self.root\n",
    "        for i in range(suffix_start, len(text)):\n",
    "            if text[i] not in node:\n",
    "                return node, i\n",
    "            else: \n",
    "                node = node[text[i]]\n",
    "        return node, len(text)\n",
    "        \n",
    "    def __contains__(self, suffix):\n",
    "        return self.find_prefix(suffix, 0)[1] == len(suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**krótki opis** - algorytm tworzy oddzielny `Node` dla każdej litery, `link`'i są tworzone w momencie poszukiwania następnej głowy (`head`) i służą do szybszego jej znalezienia, każdy link prowadzi od prefiksu $a\\sigma$ do $\\sigma$, gdie $a$ - dowolny pojedynczy znak, $\\sigma$ - dowolny w tym pusty string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degraded McCraight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DegradedSuffixTree:\n",
    "    class _Node:\n",
    "        def __init__(self, letter=None, suffix_start=-1, pref_len=-1, parent=None, children=None):\n",
    "            self.letter = '' if not letter else letter\n",
    "            self.parent = parent\n",
    "            self.start = suffix_start\n",
    "            self.len = pref_len\n",
    "            self.children = {} if not children else children\n",
    "            self.suffix_link = None\n",
    "        \n",
    "        def __len__(self): # depth in tree, but I do it my way XD\n",
    "            return self.len # length of string builded from root to the and of this node \n",
    "        \n",
    "        def __contains__(self, key):\n",
    "            return key in self.children\n",
    "        \n",
    "        def __getitem__(self, key):\n",
    "            return self.children[key]\n",
    "        \n",
    "        def add(self, child):\n",
    "            self.children[child.letter] = child\n",
    "        \n",
    "    \n",
    "    def __init__(self, text=None):\n",
    "        self.root = self._Node(suffix_start=0, pref_len=0)\n",
    "        self.root.suffix_link = self.root\n",
    "        self.root.parent = self.root\n",
    "        \n",
    "        if text is not None:\n",
    "            self.build(text)\n",
    "    \n",
    "    def _validate_and_add(self, text):\n",
    "        if text[-1] == terminal:\n",
    "            return text\n",
    "        else:\n",
    "            return text + terminal\n",
    "        \n",
    "    def build(self, text):\n",
    "        text = self._validate_and_add(text)\n",
    "        \n",
    "        head = self.root\n",
    "        pref_len = 0 # length of matched prefix of i'th suffix \n",
    "        \n",
    "        for i in range(len(text)):\n",
    "            if pref_len == len(head) and text[i + pref_len] in head: ##TODO change\n",
    "                head, pref_len = self.slow_find(text, i, head, pref_len)\n",
    "            \n",
    "            if len(head) > pref_len:\n",
    "                head = self.split_node(text, head, pref_len)\n",
    "            self.create_leaf(text, i, head, pref_len)\n",
    "            \n",
    "            pref_len = 0 # generaly max(0, pref_len - 1) 'cause of Lemma 1 in original paper\n",
    "            head = self.root\n",
    "            pref_len = 0\n",
    "            \n",
    "        self.text = text\n",
    "    \n",
    "    def slow_find(self, text, cur_start, head, pref_len):\n",
    "        # jump to next node\n",
    "        while pref_len == len(head) and text[cur_start + pref_len] in head:\n",
    "            head = head[text[cur_start + pref_len]]\n",
    "            pref_len += 1\n",
    "            # go until the end of node searching for new head\n",
    "            while pref_len < len(head) and text[cur_start + pref_len] == text[head.start + pref_len]:\n",
    "                pref_len += 1\n",
    "        return head, pref_len\n",
    "    \n",
    "    def split_node(self, text, node, pref_len):\n",
    "        parent = node.parent\n",
    "        new_node = self._Node(suffix_start=node.start, pref_len=pref_len, \n",
    "                              letter=text[node.start + len(parent)], parent=parent)\n",
    "        parent.add(new_node)\n",
    "        node.parent = new_node\n",
    "        node.letter = text[node.start + pref_len]\n",
    "        new_node.add(node)\n",
    "        \n",
    "        return new_node\n",
    "    \n",
    "    def create_leaf(self, text, suffix_start, head, pref_len):\n",
    "        leaf = self._Node(suffix_start=suffix_start, pref_len=len(text)-suffix_start,\n",
    "                          letter=text[suffix_start+pref_len])\n",
    "        leaf.parent = head\n",
    "        head.add(leaf)\n",
    "        return leaf # just in case\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        node = self.root\n",
    "        \n",
    "        for d, l in enumerate(key):\n",
    "            if d == len(node):\n",
    "                if l not in node:\n",
    "                    return False\n",
    "                node = node[l]\n",
    "            else:\n",
    "                if l != self.text[node.start + d]:\n",
    "                    return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**krótki opis** - algorytm McCraight'a bez używania elementów `link` oraz metody `fast_find`. Testy niżej pokazują że znacznie pogorsza to czas działania (algorytm nie jest liniowy względem danych wejściowych, bo nie możemy gwarantować stałej złożoności znalezienia następnej główy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McCraight algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuffixTree:\n",
    "    class _Node:\n",
    "        def __init__(self, letter=None, suffix_start=-1, pref_len=-1, parent=None, children=None):\n",
    "            self.letter = '' if not letter else letter\n",
    "            self.parent = parent\n",
    "            self.start = suffix_start\n",
    "            self.len = pref_len\n",
    "            self.children = {} if not children else children\n",
    "            self.suffix_link = None\n",
    "        \n",
    "        def __len__(self): # depth in tree, but I do it my way XD\n",
    "            return self.len # length of string builded from root to the and of this node \n",
    "        \n",
    "        def __contains__(self, key):\n",
    "            return key in self.children\n",
    "        \n",
    "        def __getitem__(self, key):\n",
    "            return self.children[key]\n",
    "        \n",
    "        def add(self, child):\n",
    "            self.children[child.letter] = child\n",
    "        \n",
    "    \n",
    "    def __init__(self, text=None):\n",
    "        self.root = self._Node(suffix_start=0, pref_len=0)\n",
    "        self.root.suffix_link = self.root\n",
    "        self.root.parent = self.root\n",
    "        \n",
    "        if text is not None:\n",
    "            self.build(text)\n",
    "    \n",
    "    def _validate_and_add(self, text):\n",
    "        if text[-1] == terminal:\n",
    "            return text\n",
    "        else:\n",
    "            return text + terminal\n",
    "        \n",
    "    def build(self, text):\n",
    "        text = self._validate_and_add(text)\n",
    "        \n",
    "        head = self.root\n",
    "        pref_len = 0 # length of matched prefix of i'th suffix \n",
    "        \n",
    "        for i in range(len(text)):\n",
    "            if pref_len == len(head) and text[i + pref_len] in head:\n",
    "                head, pref_len = self.slow_find(text, i, head, pref_len)\n",
    "            \n",
    "            if len(head) > pref_len:\n",
    "                head = self.split_node(text, head, pref_len)\n",
    "            self.create_leaf(text, i, head, pref_len)\n",
    "            \n",
    "            if head.suffix_link is None:\n",
    "                self.fast_find(text, head, pref_len)\n",
    "            head = head.suffix_link\n",
    "            pref_len = len(head) # generaly max(0, pref_len - 1) 'cause of Lemma 1 in original paper\n",
    "        \n",
    "        self.text = text\n",
    "    \n",
    "    def slow_find(self, text, cur_start, head, pref_len):\n",
    "        # jump to next node\n",
    "        while pref_len == len(head) and text[cur_start + pref_len] in head:\n",
    "            head = head[text[cur_start + pref_len]]\n",
    "            pref_len += 1\n",
    "            # go until the end of node searching for new head\n",
    "            while pref_len < len(head) and text[cur_start + pref_len] == text[head.start + pref_len]:\n",
    "                pref_len += 1\n",
    "        return head, pref_len\n",
    "    \n",
    "    def split_node(self, text, node, pref_len):\n",
    "        parent = node.parent\n",
    "        new_node = self._Node(suffix_start=node.start, pref_len=pref_len, \n",
    "                              letter=text[node.start + len(parent)], parent=parent)\n",
    "        parent.add(new_node)\n",
    "        node.parent = new_node\n",
    "        node.letter = text[node.start + pref_len]\n",
    "        new_node.add(node)\n",
    "        \n",
    "        return new_node\n",
    "    \n",
    "    def create_leaf(self, text, suffix_start, head, pref_len):\n",
    "        leaf = self._Node(suffix_start=suffix_start, pref_len=len(text)-suffix_start,\n",
    "                          letter=text[suffix_start+pref_len])\n",
    "        leaf.parent = head\n",
    "        head.add(leaf)\n",
    "        return leaf # just in case\n",
    "    \n",
    "    def fast_find(self, text, head, pref_len):\n",
    "        next_head = head.parent.suffix_link\n",
    "        \n",
    "        while len(next_head) < pref_len - 1:\n",
    "            next_head = next_head[text[head.start + len(next_head) + 1]]\n",
    "        if len(next_head) > pref_len - 1:\n",
    "            next_head = self.split_node(text, next_head, pref_len - 1)\n",
    "        head.suffix_link = next_head\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        node = self.root\n",
    "        \n",
    "        for d, l in enumerate(key):\n",
    "            if d == len(node):\n",
    "                if l not in node:\n",
    "                    return False\n",
    "                node = node[l]\n",
    "            else:\n",
    "                if l != self.text[node.start + d]:\n",
    "                    return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**krótki opis** - algotyrm konstrukcji drzewa wszystkich sufiksów przedstawiony [Edwardem McCraightem, w 1976](https://dl.acm.org/doi/10.1145/321941.321946). Zapewnia liniową złożoność budowania drzewa, i ~15% mniejszą złożoność pamięciową w porównaniu z innymi liniowymi metodami  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "TEST1 = 'bbb$'\n",
    "TEST2 = 'aabbabd'\n",
    "TEST3 = 'ababcd'\n",
    "TEST4 = 'abcbccd'\n",
    "max_test_num = 10000\n",
    "TEST5 = 'b'*5 + 'aba' + 'b'*3 + 'a'*2 + 'b'*5 + 'c'\n",
    "with open('1997_714.txt') as f:\n",
    "    TEST6 = f.read()\n",
    "\n",
    "def test(test_class, num_tests=None):\n",
    "    num_tests = num_tests if num_tests else 5\n",
    "    for test_num, s in enumerate([TEST1, TEST2, TEST3, TEST4, TEST5, TEST6][:num_tests]):\n",
    "        print(f'Building tree for TEST{test_num+1}')\n",
    "        print('Build time:')\n",
    "        %timeit index = test_class(s)\n",
    "        index = test_class(s)\n",
    "        n = min(max_test_num, len(s))\n",
    "        if max_test_num < len(s):\n",
    "            for i in range(0, n):\n",
    "                r = random.randint(0, len(s))\n",
    "                t = s[r:]\n",
    "                if i % 1000 == 0:\n",
    "                    print(f'search time for suffix len: {len(t)}')\n",
    "                    %timeit t in index\n",
    "                \n",
    "                if not t in index:\n",
    "                    return False\n",
    "        else:\n",
    "            for i in range(0, n):\n",
    "                t = s[i:]\n",
    "                if i % 1000 == 0:\n",
    "                    print(f'search time for suffix len: {len(t)}')\n",
    "                    %timeit t in index\n",
    "                \n",
    "                if not t in index:\n",
    "                    return False\n",
    "            \n",
    "        if s is TEST5:\n",
    "            if TEST1 in index:\n",
    "                return False\n",
    "        else:\n",
    "            if TEST5 in index:\n",
    "                return False\n",
    "        print(f'Test num {test_num+1} passed')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tree for TEST1\n",
      "Build time:\n",
      "28.5 µs ± 363 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 4\n",
      "2.09 µs ± 64.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 1 passed\n",
      "Building tree for TEST2\n",
      "Build time:\n",
      "63.9 µs ± 2.47 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 7\n",
      "3.17 µs ± 161 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 2 passed\n",
      "Building tree for TEST3\n",
      "Build time:\n",
      "55.1 µs ± 6.18 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 6\n",
      "2.68 µs ± 7.58 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 3 passed\n",
      "Building tree for TEST4\n",
      "Build time:\n",
      "68.1 µs ± 11.8 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 7\n",
      "3.13 µs ± 103 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 4 passed\n",
      "Building tree for TEST5\n",
      "Build time:\n",
      "282 µs ± 15.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "search time for suffix len: 19\n",
      "6.92 µs ± 37.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 5 passed\n",
      "Tests passed\n"
     ]
    }
   ],
   "source": [
    "if test(Trie, 5): # test(Trie, 6) U can do this but this takes eternity to build and a bit MORE then all your RAM  \n",
    "    print('Tests passed') \n",
    "else:\n",
    "    print('Tests failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tree for TEST1\n",
      "Build time:\n",
      "18.4 µs ± 539 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "search time for suffix len: 4\n",
      "2.15 µs ± 78.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 1 passed\n",
      "Building tree for TEST2\n",
      "Build time:\n",
      "28.3 µs ± 235 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 7\n",
      "2.73 µs ± 34.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 2 passed\n",
      "Building tree for TEST3\n",
      "Build time:\n",
      "21.4 µs ± 221 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 6\n",
      "2.43 µs ± 15.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 3 passed\n",
      "Building tree for TEST4\n",
      "Build time:\n",
      "25.3 µs ± 884 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 7\n",
      "2.64 µs ± 109 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 4 passed\n",
      "Building tree for TEST5\n",
      "Build time:\n",
      "102 µs ± 3.93 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 19\n",
      "7.28 µs ± 315 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 5 passed\n",
      "Building tree for TEST6\n",
      "Build time:\n",
      "4.5 s ± 307 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "search time for suffix len: 42374\n",
      "14.8 ms ± 437 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "search time for suffix len: 100713\n",
      "33.7 ms ± 351 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 103123\n",
      "33.4 ms ± 139 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 125446\n",
      "41.9 ms ± 709 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 198328\n",
      "66.1 ms ± 958 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 79730\n",
      "26.7 ms ± 394 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 167951\n",
      "56.2 ms ± 957 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 156211\n",
      "51.3 ms ± 213 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 100869\n",
      "33.2 ms ± 70.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 148406\n",
      "49.3 ms ± 646 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Test num 6 passed\n",
      "Tests passed\n"
     ]
    }
   ],
   "source": [
    "if test(DegradedSuffixTree, num_tests=6):\n",
    "    print('Tests passed')\n",
    "else:\n",
    "    print('Tests failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tree for TEST1\n",
      "Build time:\n",
      "20.1 µs ± 195 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 4\n",
      "1.94 µs ± 10.9 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "Test num 1 passed\n",
      "Building tree for TEST2\n",
      "Build time:\n",
      "31.2 µs ± 216 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 7\n",
      "2.71 µs ± 19.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 2 passed\n",
      "Building tree for TEST3\n",
      "Build time:\n",
      "24 µs ± 213 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 6\n",
      "2.42 µs ± 16.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 3 passed\n",
      "Building tree for TEST4\n",
      "Build time:\n",
      "27.3 µs ± 277 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 7\n",
      "2.56 µs ± 23.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 4 passed\n",
      "Building tree for TEST5\n",
      "Build time:\n",
      "92.7 µs ± 280 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "search time for suffix len: 19\n",
      "6.83 µs ± 28.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "Test num 5 passed\n",
      "Building tree for TEST6\n",
      "Build time:\n",
      "1.25 s ± 51.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "search time for suffix len: 8115\n",
      "2.84 ms ± 63.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "search time for suffix len: 94277\n",
      "32.1 ms ± 566 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 24757\n",
      "8.41 ms ± 215 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "search time for suffix len: 21508\n",
      "7.53 ms ± 264 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "search time for suffix len: 139203\n",
      "47.9 ms ± 1.41 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 5378\n",
      "1.78 ms ± 12.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "search time for suffix len: 29947\n",
      "9.99 ms ± 122 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "search time for suffix len: 165972\n",
      "54.7 ms ± 343 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 95619\n",
      "31.5 ms ± 116 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "search time for suffix len: 19428\n",
      "6.43 ms ± 86.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Test num 6 passed\n",
      "Tests passed\n"
     ]
    }
   ],
   "source": [
    "if test(SuffixTree, num_tests=6):\n",
    "    print('Tests passed')\n",
    "else:\n",
    "    print('Tests failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać z testów każde drzewo działa poprawnie, bo da się w nim znaleść każdy istniejący suffix. Dla `Trie` nie był przeprowadzony test na załączonym pliku (test numer 6), bo nie posiadam takiej ilości RAM. 1/20 tekstu po zbudowaniu na nim `Trie` zajmuje około 15 GB RAM. \n",
    "\n",
    "**Analiza czasu działania**:\n",
    "\n",
    "* wszystkie struktury mają podobny czas wyszukiwania chociaż przez narzut przechodzenia do kolejnych dzieci `Trie` wydaje się być najwolniejszym.\n",
    "\n",
    "* Czas budowania `Trie` rośnie drastycznie wraz z wzrostem rozmiaru tekstu. Teoretyczna złożoność czasawa algorytmu wynosi $O(N^{2})$, co sprawdza się w praktyce.\n",
    "\n",
    "* Czas budowania `DegradedSuffixTree` (bez `fast_find` i `link`) w najgorszym przypadku wynosi $O(N^{2})$, ale testy pokazują że najgorszy przypadek w rzeczywistości nie zachodzi. Także struktura jest mniej pamięciożerna bo nie trzyma substringi, tylko indeksy początku i końca(długośc) w tekście zródłowym, czyli ne powiela kopij tekstu i nie trzyma każdy symbol w oddzielnym `Node`.\n",
    "\n",
    "* Czas budowania `SuffixTree` metodą McCraight'a wynosi $O(N)$ co w rzeczywistości można zaobserwować patrząc na wynik ostatniego testu (2M symboli), czas wykonania jest ~4 razy mniejszy niż w przypadku bez używania `fast_find` i kilkaset+ razy szybszy od `Trie` (nie udalo się dostać wyników dla tak wielkiego tekstu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
